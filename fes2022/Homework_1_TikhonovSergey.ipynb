{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfkVztCXxMot"
   },
   "source": [
    "# Домашнее задание №2: линейная регрессия и векторное дифференцирование (10 баллов).\n",
    "\n",
    "**Дедлайн для всех групп: 29 сентября в 23:59**\n",
    "\n",
    "* Максимальное количество баллов за задания в ноутбуке - 11, но больше 10 оценка не ставится, поэтому для получения максимальной оценки можно сделать не все задания.\n",
    "\n",
    "* Некоторые задания будут по вариантам (всего 4 варианта). Чтобы выяснить свой вариант, посчитайте количество букв в своей фамилии, возьмете остаток от деления на 4 и прибавьте 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "72srIc570YD9"
   },
   "source": [
    "Выполнил: Тихонов Сергей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZSvCsbo2xMov"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6htHt4rxMov"
   },
   "source": [
    "## Многомерная линейная регрессия из sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "psdR9cz_xMov"
   },
   "source": [
    "Применим многомерную регрессию из sklearn для стандартного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BXLxlJkHxMow",
    "outputId": "b9144558-caa3-4354-910e-ef81c1d4b115"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 100) (10000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(n_samples = 10000)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XrLMi1TxMow"
   },
   "source": [
    "У нас 10000 объектов и 100 признаков. Для начала решим задачу аналитически \"из коробки\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KdSFGo01xMow",
    "outputId": "5834a34d-6349-4be3-f830-2dc4d8e9508b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4090202783179854e-25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 7.73439831e-14, -4.26325641e-14,  9.23705556e-14,  1.42108547e-14,\n",
       "        3.55271368e-14, -4.97379915e-14, -5.68434189e-14,  4.11313962e+01,\n",
       "       -4.61852778e-14, -3.19744231e-14, -1.59872116e-14, -6.21724894e-14,\n",
       "       -1.11910481e-13, -7.10542736e-15,  5.41788836e-14,  3.37507799e-14,\n",
       "       -1.06581410e-13, -1.49213975e-13, -1.59872116e-14, -1.06581410e-14,\n",
       "       -3.90798505e-14, -9.76996262e-14, -4.97379915e-14,  4.26325641e-14,\n",
       "       -7.10542736e-15,  1.42108547e-14,  9.44415381e+01,  2.90878432e-14,\n",
       "       -2.30926389e-14, -3.90798505e-14, -3.19744231e-14,  2.25404796e+00,\n",
       "        1.42108547e-14, -7.81597009e-14, -7.99360578e-14, -5.06261699e-14,\n",
       "        5.88034064e+01,  6.75015599e-14,  9.44882996e+01,  3.14392419e+01,\n",
       "        1.33226763e-14, -1.24344979e-14, -1.06581410e-13,  5.68434189e-14,\n",
       "       -6.39488462e-14,  2.13162821e-14,  1.53654867e-13, -9.23705556e-14,\n",
       "        1.42108547e-14,  6.75015599e-14, -5.06261699e-14,  9.99200722e-15,\n",
       "       -3.37507799e-14,  4.44089210e-14,  9.35322705e+01,  7.10542736e-14,\n",
       "        8.88178420e-14, -3.73034936e-14, -2.13162821e-14, -9.50350909e-14,\n",
       "        3.55271368e-14,  7.19424520e-14,  1.33226763e-15, -1.17239551e-13,\n",
       "        4.97379915e-14,  2.13162821e-14, -3.55271368e-15, -7.10542736e-15,\n",
       "        6.75015599e-14,  7.53530347e+01,  1.13242749e-14,  4.97379915e-14,\n",
       "       -1.13686838e-13, -5.32907052e-14, -3.55271368e-15,  1.15463195e-14,\n",
       "       -1.20792265e-13,  3.37507799e-14,  2.84217094e-14,  7.46069873e-14,\n",
       "       -1.77635684e-14,  4.40479013e+01, -5.32907052e-14, -8.17124146e-14,\n",
       "       -2.66453526e-15, -2.93098879e-14, -1.77635684e-14, -2.48689958e-14,\n",
       "       -6.79456491e-14, -7.10542736e-14,  4.26325641e-14, -4.97379915e-14,\n",
       "        3.55271368e-14,  6.70375013e+01, -1.06581410e-14,  1.26121336e-13,\n",
       "        1.42108547e-14, -3.01980663e-14,  5.68434189e-14, -1.77635684e-15])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "reg = LinearRegression().fit(X, y)\n",
    "print(mean_squared_error(y, reg.predict(X)))\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-cTXhYWxMow"
   },
   "source": [
    "Теперь попробуем обучить линейную регрессию методом градиентного спуска \"из коробки\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YzDCIg94xMow",
    "outputId": "ca9b5379-5750-4f7e-a69a-19e46fa41e2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2407172406143024e-12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-8.76182015e-08, -3.62160680e-08, -6.97482662e-08,  1.36085298e-08,\n",
       "        2.50436321e-09, -3.17873933e-09,  4.02099556e-09,  4.11313957e+01,\n",
       "        7.89504003e-09,  4.22724955e-08,  5.60872456e-08,  2.09859630e-08,\n",
       "        3.69399382e-09,  1.50009840e-08,  9.46655792e-08,  6.51601005e-08,\n",
       "        1.50555840e-09,  1.21854253e-08, -5.44350952e-09, -2.87193120e-08,\n",
       "        3.37920104e-08, -1.60571705e-08, -3.71936713e-09, -1.06896931e-08,\n",
       "       -2.99740712e-08, -2.82385713e-08,  9.44415372e+01,  2.47704950e-08,\n",
       "        4.53549631e-08,  4.05832720e-08, -3.00886212e-08,  2.25404797e+00,\n",
       "        1.43077307e-08, -6.57112901e-08,  5.38013920e-08,  8.78557596e-08,\n",
       "        5.88034058e+01,  4.07560921e-09,  9.44882987e+01,  3.14392416e+01,\n",
       "       -6.42111926e-09,  3.20300792e-08,  3.73041914e-08,  3.27720965e-08,\n",
       "        1.86115876e-09, -3.19035243e-08,  5.34942349e-09,  4.98348129e-10,\n",
       "        2.28947379e-08,  3.32766922e-08,  2.93533883e-08,  6.21251399e-08,\n",
       "        4.71718484e-08, -2.90292552e-08,  9.35322696e+01, -1.81170116e-08,\n",
       "        5.05550287e-08,  5.71106136e-08,  2.05707944e-08, -2.46552384e-08,\n",
       "        3.87031990e-08, -2.95145903e-08,  5.28731605e-08,  2.78030910e-08,\n",
       "       -1.21177870e-08,  1.77257909e-08, -5.05944607e-08,  4.33352262e-08,\n",
       "       -4.01446757e-08,  7.53530339e+01,  2.62811081e-08, -4.40060368e-08,\n",
       "       -2.97430784e-08, -1.69130375e-08,  2.78724892e-08,  3.63845674e-08,\n",
       "        2.16069803e-08, -4.36160519e-09, -3.11635840e-08, -1.30978204e-08,\n",
       "       -1.76819903e-08,  4.40479008e+01,  4.77314362e-08, -4.61799032e-08,\n",
       "        3.07279621e-08,  2.81129804e-08,  3.04561632e-08, -3.14928985e-08,\n",
       "       -2.63428114e-08, -5.27317701e-08,  4.18551519e-09, -1.89412008e-08,\n",
       "       -5.80497466e-09,  6.70375007e+01, -1.55595472e-08,  3.88589124e-08,\n",
       "        1.64345892e-08,  3.12162277e-08, -4.26524423e-08,  5.48455381e-08])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "reg = SGDRegressor(alpha=0.00000001).fit(X, y)\n",
    "print(mean_squared_error(y, reg.predict(X)))\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3EmPAjgxMow"
   },
   "source": [
    "***Задание 1 (0.5 балла).*** Объясните, чем вызвано различие двух полученных значений метрики?\n",
    "\n",
    "\n",
    "***Задание 2 (0.5 балла).*** Подберите гиперпараметры в методе градиентного спуска так, чтобы значение MSE было близко к значению MSE, полученному при обучении LinearRegression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7zxL65pxQc9"
   },
   "source": [
    "**Задание 1**\n",
    "В первом случае веса считаются аналитическим путём:\n",
    "$$\n",
    "w = (X'X)^{-1}X'y\n",
    "$$ \n",
    "Во втором с помощью итеративного метода (стохастического градиентного спуска), когда градиент считается не по всем объектам, а по некоторому батчу. Таким образом, минимуму функции могут отличаться. Поэтому важен осмысленный подбор гиперпараметра $\\alpha$, чтобы за максимальное количество иттераций метод успел сойтись.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ebiqa1VczzFE"
   },
   "source": [
    "**Задание 2** Теперь попробуем подобрать параметр $\\alpha$, чтобы MSE совпадали:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jk2c1Gejz9__",
    "outputId": "59c76b50-3c6f-4621-8bc4-cce4d2b265e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8272469092983366e-12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-8.32372704e-08, -3.44052669e-08, -6.62608565e-08,  1.29281072e-08,\n",
       "        2.37914375e-09, -3.01980652e-09,  3.81994836e-09,  4.11313958e+01,\n",
       "        7.50029458e-09,  4.01588826e-08,  5.32828798e-08,  1.99366697e-08,\n",
       "        3.50929366e-09,  1.42509412e-08,  8.99323090e-08,  6.19020836e-08,\n",
       "        1.43028522e-09,  1.15761630e-08, -5.17132582e-09, -2.72833522e-08,\n",
       "        3.21024056e-08, -1.52543042e-08, -3.53339820e-09, -1.01552004e-08,\n",
       "       -2.84753686e-08, -2.68266366e-08,  9.44415372e+01,  2.35319722e-08,\n",
       "        4.30872130e-08,  3.85541097e-08, -2.85841733e-08,  2.25404797e+00,\n",
       "        1.35923280e-08, -6.24257398e-08,  5.11113181e-08,  8.34629521e-08,\n",
       "        5.88034058e+01,  3.87183267e-09,  9.44882988e+01,  3.14392416e+01,\n",
       "       -6.10004572e-09,  3.04285819e-08,  3.54389885e-08,  3.11334951e-08,\n",
       "        1.76810119e-09, -3.03083390e-08,  5.08194638e-09,  4.73421969e-10,\n",
       "        2.17500046e-08,  3.16128480e-08,  2.78857227e-08,  5.90188796e-08,\n",
       "        4.48132562e-08, -2.75777924e-08,  9.35322696e+01, -1.72111696e-08,\n",
       "        4.80272894e-08,  5.42550798e-08,  1.95422600e-08, -2.34224688e-08,\n",
       "        3.67680383e-08, -2.80388638e-08,  5.02295028e-08,  2.64129312e-08,\n",
       "       -1.15118999e-08,  1.68395005e-08, -4.80647268e-08,  4.11684559e-08,\n",
       "       -3.81374370e-08,  7.53530340e+01,  2.49670674e-08, -4.18057379e-08,\n",
       "       -2.82559235e-08, -1.60673895e-08,  2.64788560e-08,  3.45653382e-08,\n",
       "        2.05266204e-08, -4.14353466e-09, -2.96054085e-08, -1.24429328e-08,\n",
       "       -1.67978872e-08,  4.40479009e+01,  4.53448603e-08, -4.38709027e-08,\n",
       "        2.91915720e-08,  2.67073262e-08,  2.89333543e-08, -2.99182447e-08,\n",
       "       -2.50256683e-08, -5.00951706e-08,  3.97623729e-09, -1.79941329e-08,\n",
       "       -5.51472986e-09,  6.70375007e+01, -1.47815617e-08,  3.69159729e-08,\n",
       "        1.56128817e-08,  2.96554093e-08, -4.05198211e-08,  5.21032707e-08])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "reg = SGDRegressor(alpha=0.0000000095).fit(X, y)\n",
    "print(mean_squared_error(y, reg.predict(X)))\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgNQBA-7xMox"
   },
   "source": [
    "## Ваша многомерная линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11sp9YRexMox"
   },
   "source": [
    "***Задание 3 (5 баллов)***. Напишите собственную многомерную линейную регрессию, оптимизирующую MSE методом *градиентного спуска*. Для этого используйте шаблонный класс. \n",
    "\n",
    "Критерий останова: либо норма разности весов на текущей и предыдущей итерациях меньше определенного значения (первый и третий варианты), либо модуль разности функционалов качества (MSE) на текущей и предыдущей итерациях меньше определенного значения (второй и четвертый варианты). Также предлагается завершать обучение в любом случае, если было произведено слишком много итераций.\n",
    "\n",
    "***Задание 4 (2 балла)***. Добавьте l1 (первый и четвертый варианты) или l2 (второй и третий варианты) регуляризацию. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "id": "MJDzFJIGxMox"
   },
   "outputs": [],
   "source": [
    "class LinearRegression(object):\n",
    "    def __init__(self, alpha, l_ratio, tol=0.001, max_iter=1000):\n",
    "        '''\n",
    "        Для начала необходимо инициализировать параметры\n",
    "        alpha - это learning rate или шаг обучения\n",
    "        l_ratio - параметр регуляризации\n",
    "        tol - значение для критерия останова\n",
    "        max_iter - максимальное количество итераций обучения\n",
    "        '''\n",
    "        \n",
    "        self.l_ratio = l_ratio\n",
    "        self.alpha = alpha\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "        self.w = None\n",
    "        self.loss_history = None\n",
    "             \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Метод для обучения линейной регрессии\n",
    "        X - матрица признаков\n",
    "        y - вектор правильных ответов\n",
    "        '''\n",
    "        X = np.hstack([X, np.ones([X.shape[0], 1])])\n",
    "        self.w = np.random.uniform(-2, 2, (X.shape[1]))\n",
    "        self.weight_history = [self.w]\n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "\n",
    "            w_no_bias = self.w.copy()\n",
    "            w_no_bias[-1] = 0\n",
    "            self.w = self.w - self.l_ratio * (2 * (X.T @ (X @ self.w - y)) / len(X) + self.alpha * np.sign(w_no_bias))\n",
    "            self.weight_history.append(self.w)\n",
    "\n",
    "            if np.abs(mean_squared_error(y, X @ self.weight_history[-1]) - mean_squared_error(y, X @ self.weight_history[-2])) < self.tol:\n",
    "                break\n",
    "\n",
    "        return self.weight_history\n",
    "   \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Метод для предсказаний линейной регрессии\n",
    "        X - матрица признаков\n",
    "        '''\n",
    "        X = np.hstack([X, np.ones([X.shape[0], 1])])\n",
    "        \n",
    "        return X @ self.w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pa3MOuS3fqsL"
   },
   "source": [
    "**Важные комментарии по имплементации класса:**\n",
    "\n",
    "1. X = np.hstack([X, np.ones([X.shape[0], 1])]) - добавили столбец из единиц для константного признака (bias)\n",
    "2. w_no_bias - из лекций известно, что bias не регуляризируется, поэтому убираем w_no_bias[-1] = 0 последний элемент из вектора весов.\n",
    "3. Считаю, что в инициализации параметров класса ошибка. Alpha - это параметр регуляризации (как и везде в sklearn), а l_ratio - собственно learning rate.\n",
    "4. Регуляризацию реализовал следующим образом: если $\\alpha = 0$, то это обычная регрессия (оценки совпадают с OLS, так как функционал и градиент совпадают). Если $\\alpha \\neq 0$, то имеет место регрессия с регуляризацией, в моём варианте Lasso. Очень удобно и без лишних if :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-jsMBSRlxMoy",
    "outputId": "1359aaa0-1027-4d9b-9095-e7ce5c84c35c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are amazing! Great work!\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "my_reg = LinearRegression(alpha=0, l_ratio=0.5) \n",
    "my_reg.fit(X, y)\n",
    "assert mean_squared_error(y, my_reg.predict(X)) < 1e-3\n",
    "print('You are amazing! Great work!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nOCAioPrhQX1",
    "outputId": "e3401e0b-3bba-4a35-8e92-235531fea73e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4487916152541083e-06"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "mean_squared_error(y, my_reg.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9dBDmysxf2V1",
    "outputId": "227c42b7-7c38-4cfc-b0ef-533a6dbb614b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 215.19841037, -378.21747116, -137.70075467, ...,  250.4543156 ,\n",
       "        212.81785398, -350.63415562])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qsuAaCzdfzqw",
    "outputId": "c57b4ef1-fc19-43d3-9fc2-5c0f4585b93a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 215.19758348, -378.21682991, -137.70197055, ...,  250.45348715,\n",
       "        212.81078084, -350.63018008])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "my_reg.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIXY_u3_xMoy"
   },
   "source": [
    "***Задание 5 (1 балл)***. Обучите линейную регрессию из коробки\n",
    "\n",
    "* с l1-регуляризацией (from sklearn.linear_model import Lasso, **первый и четвертый вариант**) или с l2-регуляризацией (from sklearn.linear_model import Ridge, **второй и третий вариант**)\n",
    "* со значением параметра регуляризации **0.1 - для первого и третьего варианта, 0.01 - для второго и четвертого варианта**. \n",
    "\n",
    "Обучите вашу линейную регрессию с тем же значением параметра регуляризации и сравните результаты. Сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bK_r0ghExMoy",
    "outputId": "947149c6-fd52-44c3-873a-62e440c3675a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0009984891234456107\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "reg = Lasso(alpha=0.01, tol=0.001).fit(X, y)\n",
    "print(mean_squared_error(y, reg.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u43XJqQd5dCP",
    "outputId": "0725cc72-a2c6-40cd-ef5c-aa857c1d6682"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0009668368979658105"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "my_reg_ridge = LinearRegression(alpha=0.01, l_ratio=0.25)\n",
    "my_reg_ridge.fit(X, y)\n",
    "mean_squared_error(y, my_reg_ridge.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q10_LQrNY169"
   },
   "source": [
    "**Выводы:**\n",
    "\n",
    "Результаты собственной имплементации Lasso и готовой версии из sklearn при заданном параметре регуляризации $\\lambda = 0.01$ практически не отличаются. Результат вполне ожидаем, поскольку обе версии Lasso являются иттеративными (на основе градиентного спуска), то есть одинаково сходятся на одних и тех же данных. \n",
    "\n",
    "Разница могла быть в случае сравнения Ridge, поскольку там имеется аналитическое решение, которое может не совпадать с иттеративным при плохом подборе параметров. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G12MDk3gxMoy"
   },
   "source": [
    "***Задание 6* (1 балл).***\n",
    "Пусть $P, Q \\in \\mathbb{R}^{n\\times n}$. Найдите $\\nabla_Q tr(PQ)$\n",
    "\n",
    "Сначала посчитаем $d(tr(PQ)$\n",
    "\n",
    "Зная, что $tr(...)$ - линейное отображение по определению (сумма элементов, лежащих на главной диагонали) и что $d(...)$ - тоже линейное отображение по определению (линейная часть дифференцируемой функциий), можно заключить, что они коммутатируют:\n",
    "\n",
    "$$d(tr(PQ)) = tr(d(PQ)) = tr(PdQ) = tr(PdQ)$$\n",
    "\n",
    "$tr(PdQ)$ - сумма попарных произведений элементов главной диагонали матрицы, образованной произведением $P dQ$, а значит:\n",
    "\n",
    "$$tr(PdQ) = <P^T, dQ>$$\n",
    "\n",
    "Воспользуемся фактом, что $<\\nabla_x f(x),dx>$:\n",
    "\n",
    "$$\\nabla_Qtr(PQ) = P^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BX-9ANkIxMoz"
   },
   "source": [
    "***Задание 7* (1 балл).***\n",
    "Пусть $x, y \\in \\mathbb{R}^{n}, M \\in \\mathbb{R}^{n\\times n}$. Найдите $\\nabla_M x^T M y$\n",
    "\n",
    "Note: \n",
    "\n",
    "1) $x^TMx$ - скаляр, так как вектор размера $1 \\times n$ умножается на матрицу размера $n \\times n$ умножается на вектор размера $n \\times 1$.\n",
    "\n",
    "2) $tr(\\text{скаляр}) = \\text{скаляр}$\n",
    "\n",
    "3) $tr(ABC) = tr(BCA) = tr(CAB)$ (для матриц подходящего размера)\n",
    "\n",
    "Сначала посчитаем $d(x^T M y)$\n",
    "\n",
    "$$d(x^T M y) = \\text{Воспользуемся Note 1 и 2} = d(tr(x^T M y)) = \\text{Воспользуемся Note 3} = d(tr(yx^TM)) $$\n",
    "\n",
    "Воспользуемся результатом задания 6:\n",
    "\n",
    "$$tr(yx^TM) = <xy^T, M>$$\n",
    "\n",
    "Воспользуемся фактом, что $<\\nabla_x f(x),dx>$:\n",
    "\n",
    "$$\\nabla_M x^T M y = xy^T$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvRvcddYxMoz"
   },
   "source": [
    "Решения заданий 6 и 7 можно написать на листочке и отправить в anytask вместе с заполненным ноутбуком."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Homework_1_TikhonovSergey.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
